#!/usr/bin/env python3
"""
Vers√£o simplificada para Streamlit Cloud - Chatbot Epson
Sem depend√™ncias pesadas como ChromaDB
"""

import streamlit as st
import google.generativeai as genai
import time
import re
import os

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Chatbot Epson - Suporte T√©cnico",
    page_icon="üñ®Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√£o da API Gemini
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    GEMINI_API_KEY = "AIzaSyDjejxDFqTSg_i-KDnS2QqsXdiWLydIrSk"

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Rate limiting
last_request_time = 0
MIN_REQUEST_INTERVAL = 2

# Metadados das impressoras
PRINTER_METADATA = {
    'L3110': 'Epson L3110 - Multifuncional EcoTank',
    'L3150': 'Epson L3150 - Multifuncional EcoTank com Wi-Fi',
    'L3250': 'Epson L3250/L3251 - Multifuncional EcoTank com Wi-Fi',
    'L375': 'Epson L375 - Multifuncional EcoTank',
    'L4150': 'Epson L4150 - Multifuncional EcoTank com ADF',
    'L4260': 'Epson L4260 - Multifuncional EcoTank com ADF',
    'L5190': 'Epson L5190 - Multifuncional com Fax',
    'L5290': 'Epson L5290 - Multifuncional com Fax e Ethernet',
    'L6490': 'Epson L6490 - Multifuncional A3',
    'L805': 'Epson L805 - Fotogr√°fica',
    'L1300': 'Epson L1300 - A3+',
    'L396': 'Epson L396 - Multifuncional compacta'
}

# Inicializa session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'selected_printer' not in st.session_state:
    st.session_state.selected_printer = None
if 'response_mode' not in st.session_state:
    st.session_state.response_mode = 'detalhado'

def check_printer_context(query):
    """Verifica se a pergunta √© sobre impressoras"""
    try:
        prompt = f"""Analise se a pergunta √© sobre impressoras. Responda APENAS "SIM" ou "N√ÉO".

Pergunta: "{query}"

√â sobre impressoras, problemas de impress√£o, tinta, papel, configura√ß√£o de impressoras, scanner ou c√≥pia?"""
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=10
            )
        )
        
        if response and response.text:
            return "SIM" in response.text.upper()
        return True
        
    except Exception as e:
        print(f"Erro ao verificar contexto: {e}")
        return True

def detect_printer_from_query(query):
    """Detecta modelo de impressora na query"""
    query_upper = query.upper()
    
    for model_key in PRINTER_METADATA.keys():
        if model_key in query_upper:
            return model_key
    
    # Busca por n√∫meros de modelo
    import re
    numbers = re.findall(r'\b[L]?\d{3,4}\b', query_upper)
    for num in numbers:
        for model_key in PRINTER_METADATA.keys():
            if num in model_key:
                return model_key
    
    return None

def process_query_simple(query, printer_model, mode='detalhado'):
    """Processa pergunta usando apenas Gemini (sem ChromaDB)"""
    global last_request_time
    
    try:
        # Rate limiting
        current_time = time.time()
        if current_time - last_request_time < MIN_REQUEST_INTERVAL:
            time.sleep(MIN_REQUEST_INTERVAL - (current_time - last_request_time))
        
        printer_name = PRINTER_METADATA.get(printer_model, printer_model)
        
        if mode == 'rapido':
            prompt = f"""Voc√™ √© um especialista em impressoras Epson {printer_name}.
Responda a pergunta de forma BREVE e DIRETA em 3-4 passos.

Pergunta: {query}

Resposta concisa:"""
            max_tokens = 300
        else:
            prompt = f"""Voc√™ √© um especialista em impressoras Epson {printer_name}.
Forne√ßa uma resposta DETALHADA e COMPLETA com passos numerados.

Pergunta: {query}

Resposta detalhada:"""
            max_tokens = 800
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=max_tokens
            )
        )
        
        last_request_time = time.time()
        
        if response and response.text:
            return response.text, "üìö Conhecimento base Gemini"
        else:
            return None, "Erro ao gerar resposta"
            
    except Exception as e:
        return None, f"Erro: {e}"

def main():
    # Header
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("üñ®Ô∏è Chatbot Epson")
        st.markdown("**Sistema de Suporte T√©cnico**")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # Sele√ß√£o de impressora
        st.subheader("üñ®Ô∏è Impressora")
        
        printer_options = ['Detec√ß√£o Autom√°tica'] + list(PRINTER_METADATA.keys())
        selected = st.selectbox(
            "Selecione o modelo:",
            options=printer_options,
            index=0
        )
        
        if selected != 'Detec√ß√£o Autom√°tica':
            st.session_state.selected_printer = selected
        else:
            st.session_state.selected_printer = None
        
        # Modo de resposta
        st.subheader("üí¨ Modo de Resposta")
        st.session_state.response_mode = st.radio(
            "Como deseja as respostas?",
            ['detalhado', 'rapido'],
            format_func=lambda x: 'üìñ Detalhado' if x == 'detalhado' else '‚ö° R√°pido'
        )
        
        # Limpar chat
        if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
            st.session_state.messages = []
            st.rerun()
        
        # Info
        st.markdown("---")
        st.caption("**Vers√£o:** 2.0 Cloud")
        st.caption("**Modelos suportados:**")
        for model in list(PRINTER_METADATA.keys())[:5]:
            st.caption(f"‚Ä¢ {model}")
        st.caption("...e mais")
    
    # Mensagem de boas-vindas
    if len(st.session_state.messages) == 0:
        with st.chat_message("assistant"):
            st.markdown("""üëã **Ol√°! Sou o assistente t√©cnico Epson!**
            
Posso ajudar com:
- üîß Problemas t√©cnicos
- üñ®Ô∏è Configura√ß√£o de impressoras
- üé® Qualidade de impress√£o
- üì° Conex√£o Wi-Fi
- üõ†Ô∏è Manuten√ß√£o e limpeza

**Digite sua pergunta abaixo!**""")
    
    # Exibe hist√≥rico
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message.get("source"):
                st.caption(message["source"])
    
    # Input do usu√°rio
    if prompt := st.chat_input("Digite sua pergunta sobre impressoras Epson..."):
        # Adiciona mensagem do usu√°rio
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Verifica contexto
        if not check_printer_context(prompt):
            with st.chat_message("assistant"):
                out_of_context = """ü§î **Desculpe, n√£o posso ajudar com esse assunto.**

Sou especializado em **impressoras Epson**. Posso ajudar com:
- Problemas t√©cnicos
- Configura√ß√£o
- Manuten√ß√£o
- Qualidade de impress√£o
- Conex√£o e rede

**Por favor, fa√ßa uma pergunta sobre impressoras!**"""
                st.markdown(out_of_context)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": out_of_context
                })
            st.stop()
        
        # Detecta ou usa impressora selecionada
        printer_model = st.session_state.selected_printer
        
        if not printer_model:
            detected = detect_printer_from_query(prompt)
            if detected:
                printer_model = detected
                with st.chat_message("assistant"):
                    st.info(f"üîç Detectado: **{PRINTER_METADATA.get(detected, detected)}**")
            else:
                # Usa modelo gen√©rico
                printer_model = "EcoTank"
                with st.chat_message("assistant"):
                    st.info("üí° Usando conhecimento geral sobre impressoras Epson")
        
        # Processa pergunta
        with st.spinner('ü§ñ Processando...'):
            response, source = process_query_simple(
                prompt,
                printer_model,
                st.session_state.response_mode
            )
        
        # Exibe resposta
        with st.chat_message("assistant"):
            if response:
                mode_emoji = "‚ö°" if st.session_state.response_mode == 'rapido' else "üìñ"
                printer_name = PRINTER_METADATA.get(printer_model, printer_model)
                header = f"{mode_emoji} **[{printer_name}]**\n\n"
                st.markdown(header + response)
                st.caption(source)
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": header + response,
                    "source": source
                })
            else:
                error_msg = "‚ùå Desculpe, n√£o consegui processar sua pergunta. Tente novamente."
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg,
                    "source": source
                })

if __name__ == "__main__":
    main()
