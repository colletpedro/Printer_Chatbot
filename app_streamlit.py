#!/usr/bin/env python3
"""
Chatbot Epson - Interface Streamlit
Vers√£o limpa e funcional para deploy
"""

import streamlit as st
import google.generativeai as genai

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Chatbot Epson - Suporte T√©cnico",
    page_icon="üñ®Ô∏è",
    layout="wide"
)

# Configura√ß√£o da API Gemini
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyDjejxDFqTSg_i-KDnS2QqsXdiWLydIrSk")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Lista de modelos suportados
PRINTER_MODELS = [
    "Epson L3110", "Epson L3150", "Epson L3250", "Epson L3251",
    "Epson L375", "Epson L396", "Epson L4150", "Epson L4260",
    "Epson L5190", "Epson L5290", "Epson L6490", "Epson L1300", "Epson L805"
]

# Inicializa√ß√£o do estado
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'response_mode' not in st.session_state:
    st.session_state.response_mode = "detalhado"
if 'identified_printer' not in st.session_state:
    st.session_state.identified_printer = None
if 'identification_stage' not in st.session_state:
    st.session_state.identification_stage = None
if 'collected_features' not in st.session_state:
    st.session_state.collected_features = []

def detect_printer_in_query(query):
    """Detecta se algum modelo de impressora foi mencionado na pergunta"""
    query_lower = query.lower()
    for model in PRINTER_MODELS:
        # Remove "Epson " do modelo para compara√ß√£o mais flex√≠vel
        model_simple = model.replace("Epson ", "").lower()
        # Verificar varia√ß√µes (com/sem espa√ßo, com/sem tra√ßo)
        model_variations = [
            model_simple,
            model_simple.replace(" ", ""),
            model_simple.replace("-", ""),
            model_simple.replace("l", "l "),  # L3150 ‚Üí L 3150
        ]
        for variant in model_variations:
            if variant in query_lower:
                return model
    return None

def infer_model_from_features(features):
    """Tenta inferir o modelo baseado nas caracter√≠sticas coletadas"""
    if not features:
        return None
    
    features_set = set(features) if isinstance(features, list) else {features}
    
    # Mapear caracter√≠sticas para poss√≠veis modelos
    model_hints = {
        "Epson L3150": {"wifi", "tanque", "colorida", "multifuncional"},
        "Epson L3250": {"wifi", "tanque", "colorida", "multifuncional", "nova"},
        "Epson L3110": {"tanque", "colorida", "multifuncional", "no_wifi"},
        "Epson L375": {"wifi", "tanque", "colorida", "multifuncional", "antiga"},
        "Epson L396": {"wifi", "tanque", "colorida", "multifuncional"},
        "Epson L4150": {"wifi", "tanque", "colorida", "multifuncional"},
        "Epson L4260": {"wifi", "tanque", "colorida", "multifuncional", "nova"},
        "Epson L5190": {"wifi", "tanque", "colorida", "multifuncional", "fax"},
        "Epson L5290": {"wifi", "tanque", "colorida", "multifuncional", "fax", "nova"},
        "Epson L805": {"wifi", "tanque", "colorida", "simples"},
        "Epson L1300": {"tanque", "colorida", "simples", "grande"},
    }
    
    # Encontrar melhor correspond√™ncia
    best_match = None
    best_score = 0
    
    for model, model_features in model_hints.items():
        score = len(features_set.intersection(model_features))
        if score > best_score:
            best_score = score
            best_match = model
    
    # Retornar modelo se tiver pelo menos 2 caracter√≠sticas em comum
    return best_match if best_score >= 2 else None

def analyze_user_response(prompt, stage):
    """Analisa a resposta do usu√°rio de forma inteligente e flex√≠vel"""
    prompt_lower = prompt.lower().strip()
    
    # Remover pontua√ß√£o comum para melhor matching
    import string
    prompt_clean = prompt_lower.translate(str.maketrans('', '', string.punctuation))
    
    if stage == "initial" or stage is None:
        # Verificar se usu√°rio mencionou tipo multifuncional
        multifuncional_keywords = [
            "multifuncional", "multi funcional", "multi", "3 em 1", "3em1",
            "copia", "copiar", "digitaliza", "digitalizar", "scanner", "scan",
            "xerox", "todas as fun√ß√µes", "completa", "tudo", "faz tudo"
        ]
        
        impressora_simples_keywords = [
            "s√≥ imprime", "so imprime", "apenas imprime", "apenas impressora",
            "simples", "basica", "b√°sica", "normal", "comum",
            "n√£o copia", "nao copia", "n√£o digitaliza", "nao digitaliza",
            "impressora apenas", "somente impressora", "somente imprime"
        ]
        
        # Verificar multifuncional
        for keyword in multifuncional_keywords:
            if keyword in prompt_clean:
                return "multifuncional"
        
        # Verificar impressora simples
        for keyword in impressora_simples_keywords:
            if keyword in prompt_clean:
                return "simples"
        
        # Verificar se usu√°rio disse que n√£o sabe
        nao_sei_keywords = [
            "n√£o sei", "nao sei", "n√£o lembro", "nao lembro", "esqueci",
            "n√£o fa√ßo ideia", "nao faco ideia", "n√£o tenho certeza", "nao tenho certeza",
            "talvez", "acho que"
        ]
        
        for keyword in nao_sei_keywords:
            if keyword in prompt_clean:
                return "nao_sei"
                
    elif stage in ["type_known", "type_known_multi", "type_known_simple"]:
        # Analisar caracter√≠sticas mencionadas
        features = {
            "wifi": ["wifi", "wi fi", "wi-fi", "wireless", "sem fio", "rede", "internet", "sim tem", "tem sim", "sim"],
            "no_wifi": ["n√£o tem wifi", "nao tem wifi", "sem wifi", "cabo", "usb", "n√£o", "nao"],
            "tanque": ["tanque", "tanques", "tank", "ecotank", "eco tank", "refil", "bulk", "garrafa", "sim", "tem tanque"],
            "no_tanque": ["cartucho", "cartuchos", "n√£o tem tanque", "nao tem tanque", "sem tanque"],
            "colorida": ["colorida", "colorido", "cores", "color", "cmyk", "cor", "sim colorida"],
            "pb": ["preto e branco", "pretoebranco", "pb", "p&b", "monocromatica", "mono", "s√≥ preto", "so preto"],
            "nova": ["nova", "novo", "recente", "2024", "2023", "2022", "ano passado", "mes passado", "1 ano", "2 anos"],
            "antiga": ["antiga", "antigo", "velha", "velho", "2019", "2018", "2017", "anos", "tempo", "3 anos", "4 anos", "5 anos"]
        }
        
        detected_features = []
        for feature, keywords in features.items():
            for keyword in keywords:
                if keyword in prompt_clean:
                    detected_features.append(feature)
                    break
        
        # Se detectou algo, retornar
        if detected_features:
            return detected_features
        
        # Verificar respostas simples sim/n√£o
        sim_keywords = ["sim", "yes", "claro", "tem", "possui", "exato", "isso", "correto", "afirmativo"]
        nao_keywords = ["n√£o", "nao", "no", "negativo", "sem", "n√£o tem", "nao tem"]
        
        for keyword in sim_keywords:
            if keyword in prompt_clean:
                return ["resposta_sim"]
        
        for keyword in nao_keywords:
            if keyword in prompt_clean:
                return ["resposta_nao"]
            
    elif stage in ["features_known", "features_analyzed"]:
        # Verificar tamanho mencionado
        tamanhos = {
            "compacta": ["compacta", "pequena", "pequeno", "mini", "portatil", "port√°til"],
            "media": ["media", "m√©dia", "medio", "m√©dio", "normal", "padr√£o", "padrao"],
            "grande": ["grande", "gigante", "robusta", "profissional", "escritorio", "escrit√≥rio"]
        }
        
        for tamanho, keywords in tamanhos.items():
            for keyword in keywords:
                if keyword in prompt_clean:
                    return tamanho
        
        # Verificar se usu√°rio desistiu
        desistir_keywords = [
            "desisto", "n√£o consigo", "nao consigo", "deixa pra l√°", "deixa pra la",
            "esquece", "cancela", "para", "pare", "sair"
        ]
        
        for keyword in desistir_keywords:
            if keyword in prompt_clean:
                return "desistiu"
    
    return None

def generate_funnel_question(query, stage=None, context=None):
    """Gera pergunta de afunilamento para identificar a impressora"""
    if stage is None or stage == "initial":
        return """üîç **Preciso identificar sua impressora primeiro!**
        
Para fornecer a melhor assist√™ncia, preciso saber o modelo exato da sua impressora Epson.

**Por favor, me informe:**
1. Voc√™ sabe o modelo da sua impressora? (Ex: L3150, L375, L4260, etc.)
2. Se n√£o souber, me diga: ela **copia e digitaliza** tamb√©m ou **s√≥ imprime**?
   
üí° Dica: Pode responder de forma simples como "√© multifuncional" ou "s√≥ imprime"."""
    
    elif stage == "type_known_multi":
        return """üìã **√ìtimo! Sua impressora √© multifuncional!**
        
**Agora me ajude com mais detalhes:**
- Ela tem **Wi-Fi** ou conex√£o sem fio?
- Voc√™ v√™ **tanques de tinta** na frente ou lateral?
- √â **colorida** ou s√≥ **preto e branco**?
- √â **nova** (√∫ltimos 2 anos) ou mais **antiga**?

üí° Responda o que souber, n√£o precisa ser tudo!"""
    
    elif stage == "type_known_simple":
        return """üìã **Ok! Sua impressora √© modelo simples (s√≥ imprime)!**
        
**Me ajude com mais informa√ß√µes:**
- Ela tem **tanques de tinta** vis√≠veis?
- √â **colorida** ou **preto e branco**?
- Qual o **tamanho** dela? (pequena, m√©dia, grande)

üí° Qualquer detalhe ajuda!"""
    
    elif stage == "features_analyzed":
        # Resposta baseada nas caracter√≠sticas detectadas
        if context and isinstance(context, list):
            features_text = "‚úÖ Entendi! Sua impressora tem: " + ", ".join(context)
        else:
            features_text = "‚úÖ Ok, anotei essas informa√ß√µes!"
            
        return f"""{features_text}

üéØ **√öltima etapa para identificar o modelo:**

Por favor, **procure uma etiqueta** na sua impressora com o modelo.
Normalmente est√° em um destes lugares:
- **Parte frontal** (pr√≥ximo aos bot√µes)
- **Tampa superior** (ao abrir)
- **Parte traseira** (pr√≥ximo √†s conex√µes)

O modelo come√ßa com **"L"** seguido de n√∫meros (Ex: L3150, L375, L4260)

Consegue ver? Se n√£o, me diga o **tamanho aproximado** da impressora."""
    
    elif stage == "nao_sei":
        return """ü§î **Sem problemas! Vamos descobrir juntos!**

**Me responda apenas isto:**
Sua impressora faz **c√≥pia e digitaliza√ß√£o** (scanner) al√©m de imprimir?

- Se **SIM** ‚Üí √â multifuncional
- Se **N√ÉO** ‚Üí √â impressora simples
- **N√£o sei** ‚Üí Veja se tem uma tampa em cima que abre (isso √© o scanner)

üí° Responda de forma simples!"""
    
    elif stage == "desistiu":
        return """üòî **Entendo sua dificuldade!**

**√öltima tentativa - Super Simples:**

1. **Olhe sua impressora agora**
2. **Procure qualquer n√∫mero** que comece com **"L"**
3. **Me diga esse n√∫mero**

Exemplos: L3150, L375, L805, L4260...

Se realmente n√£o conseguir, recomendo:
- Verificar a nota fiscal
- Olhar o manual
- Pedir ajuda para algu√©m pr√≥ximo

Estou aqui quando conseguir a informa√ß√£o! üñ®Ô∏è"""
    
    else:
        return """‚ùå **N√£o consigo prosseguir sem identificar sua impressora**
        
Para sua seguran√ßa, preciso saber o modelo exato antes de dar instru√ß√µes t√©cnicas.

**O que fazer:**
1. Procure o modelo na pr√≥pria impressora
2. Verifique nota fiscal ou caixa
3. Olhe nas configura√ß√µes do computador

Quando souber o modelo, volte que eu ajudo! üñ®Ô∏è"""

def generate_response(query, printer_model=None, mode="detalhado"):
    """Gera resposta usando Gemini - APENAS se souber o modelo da impressora"""
    
    # N√ÉO responde sem modelo de impressora
    if not printer_model:
        return None
    
    try:
        # Ajusta o prompt baseado no modo
        if mode == "r√°pido":
            mode_instruction = """
            Forne√ßa uma resposta BREVE e DIRETA, em no m√°ximo 3-4 frases.
            V√° direto ao ponto principal sem muitos detalhes.
            IMPORTANTE: Seja espec√≠fico para o modelo de impressora informado.
            """
        else:  # detalhado
            mode_instruction = """
            Forne√ßa uma resposta COMPLETA e DETALHADA.
            Inclua:
            - Explica√ß√£o passo a passo espec√≠fica para este modelo
            - Poss√≠veis causas do problema neste modelo espec√≠fico
            - Solu√ß√µes alternativas se existirem
            - Dicas de preven√ß√£o para este modelo
            IMPORTANTE: Todas as informa√ß√µes devem ser espec√≠ficas para o modelo informado.
            """
        
        prompt = f"""Voc√™ √© um especialista em impressoras Epson.
        
        Modelo da impressora: {printer_model}
        
        {mode_instruction}
        
        REGRA CR√çTICA: Forne√ßa informa√ß√µes ESPEC√çFICAS para o modelo {printer_model}.
        N√£o d√™ respostas gen√©ricas. Se n√£o souber algo espec√≠fico deste modelo, seja honesto.
        
        Pergunta do usu√°rio: {query}
        
        Responda em portugu√™s de forma clara e espec√≠fica para o modelo {printer_model}."""
        
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text
        else:
            return "N√£o foi poss√≠vel gerar resposta. Tente novamente."
            
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# Interface principal
st.title("üñ®Ô∏è Chatbot Epson - Suporte T√©cnico")
st.markdown("Sistema inteligente de suporte para impressoras Epson")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o de impressora
    selected_printer = st.selectbox(
        "üñ®Ô∏è Modelo da Impressora:",
        ["N√£o especificado"] + PRINTER_MODELS
    )
    
    # Atualizar impressora identificada quando selecionada manualmente
    if selected_printer != "N√£o especificado":
        st.session_state.identified_printer = selected_printer
        st.session_state.identification_stage = None
        st.success(f"‚úÖ Modelo identificado: {selected_printer}")
    elif st.session_state.identified_printer:
        st.info(f"üìå Modelo detectado: {st.session_state.identified_printer}")
    
    st.markdown("---")
    
    # Modo de resposta
    st.subheader("üí¨ Modo de Resposta")
    response_mode = st.radio(
        "Escolha o tipo de resposta:",
        ["r√°pido", "detalhado"],
        index=1,  # detalhado por padr√£o
        help="R√°pido: respostas diretas e concisas\nDetalhado: explica√ß√µes completas com passo a passo"
    )
    st.session_state.response_mode = response_mode
    
    if response_mode == "r√°pido":
        st.info("‚ö° Respostas r√°pidas e diretas")
    else:
        st.info("üìñ Respostas detalhadas com explica√ß√µes")
    
    st.markdown("---")
    
    # Limpar chat
    if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
        st.session_state.messages = []
        st.session_state.identified_printer = None
        st.session_state.identification_stage = None
        st.session_state.collected_features = []
        st.rerun()
    
    # Resetar identifica√ß√£o
    if st.session_state.identified_printer and st.button("üîÑ Trocar Impressora", use_container_width=True):
        st.session_state.identified_printer = None
        st.session_state.identification_stage = None
        st.session_state.collected_features = []
        st.rerun()
    
    # Mostrar features coletadas (para debug)
    if st.session_state.collected_features and not st.session_state.identified_printer:
        st.caption(f"üìä Caracter√≠sticas: {', '.join(st.session_state.collected_features)}")
    
    st.markdown("---")
    st.markdown("**Vers√£o:** 2.0")
    st.markdown("**Status:** ‚úÖ Online")
    st.markdown("**Modo:** Afunilamento Obrigat√≥rio")

# Mostrar mensagem inicial se n√£o houver hist√≥rico
if not st.session_state.messages and not st.session_state.identified_printer:
    with st.chat_message("assistant"):
        welcome_msg = """üëã **Ol√°! Bem-vindo ao Suporte T√©cnico Epson!**
        
Para fornecer o melhor suporte poss√≠vel, preciso identificar o modelo exato da sua impressora.

**Voc√™ pode:**
1. Selecionar o modelo na barra lateral ‚û°Ô∏è
2. Digitar o modelo diretamente (Ex: "Minha impressora √© L3150")
3. Responder algumas perguntas para eu identificar sua impressora

**Como posso ajudar voc√™ hoje?**"""
        st.markdown(welcome_msg)

# Mostrar mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio
if prompt := st.chat_input("Digite sua pergunta sobre impressoras Epson..."):
    # Adicionar mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Detectar modelo na pergunta
    detected_model = detect_printer_in_query(prompt)
    
    # Atualizar modelo identificado se detectado
    if detected_model:
        st.session_state.identified_printer = detected_model
        st.session_state.identification_stage = None
    
    # Determinar qual modelo usar
    printer_to_use = None
    if selected_printer != "N√£o especificado":
        printer_to_use = selected_printer
    elif st.session_state.identified_printer:
        printer_to_use = st.session_state.identified_printer
    elif detected_model:
        printer_to_use = detected_model
    
    # Gerar e mostrar resposta
    with st.chat_message("assistant"):
        with st.spinner("Processando..."):
            # Se temos um modelo, gerar resposta normal
            if printer_to_use:
                response = generate_response(
                    prompt, 
                    printer_to_use,
                    mode=st.session_state.response_mode
                )
                
                # Adicionar indicador do modelo usado
                response_with_model = f"**[{printer_to_use}]** {response}"
                st.markdown(response_with_model)
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.messages.append({"role": "assistant", "content": response_with_model})
            
            # Se n√£o temos modelo, iniciar afunilamento
            else:
                # Analisar resposta do usu√°rio de forma inteligente
                current_stage = st.session_state.identification_stage
                analysis = analyze_user_response(prompt, current_stage)
                
                # Processar an√°lise e atualizar est√°gio
                new_stage = current_stage
                context = None
                
                if current_stage in ["initial", None]:
                    if analysis == "multifuncional":
                        new_stage = "type_known_multi"
                        st.session_state.collected_features.append("multifuncional")
                    elif analysis == "simples":
                        new_stage = "type_known_simple"
                        st.session_state.collected_features.append("simples")
                    elif analysis == "nao_sei":
                        new_stage = "nao_sei"
                    else:
                        # Manter no est√°gio inicial se n√£o entendeu
                        new_stage = "initial"
                
                elif current_stage == "nao_sei":
                    # Segunda tentativa ap√≥s usu√°rio dizer que n√£o sabe
                    if analysis == "multifuncional":
                        new_stage = "type_known_multi"
                        st.session_state.collected_features.append("multifuncional")
                    elif analysis == "simples":
                        new_stage = "type_known_simple"
                        st.session_state.collected_features.append("simples")
                    else:
                        new_stage = "initial"  # Voltar ao in√≠cio
                
                elif current_stage in ["type_known_multi", "type_known_simple", "type_known"]:
                    if isinstance(analysis, list) and analysis:
                        # Adicionar caracter√≠sticas coletadas
                        for feature in analysis:
                            if feature not in ["resposta_sim", "resposta_nao"] and feature not in st.session_state.collected_features:
                                st.session_state.collected_features.append(feature)
                        
                        # Tentar inferir modelo com caracter√≠sticas coletadas
                        inferred_model = infer_model_from_features(st.session_state.collected_features)
                        
                        if inferred_model:
                            # Modelo identificado por infer√™ncia!
                            st.session_state.identified_printer = inferred_model
                            st.session_state.identification_stage = None
                            
                            success_msg = f"""‚úÖ **Modelo identificado: {inferred_model}!**
                            
Baseado nas caracter√≠sticas que voc√™ mencionou, identifiquei sua impressora!

Agora posso fornecer suporte espec√≠fico para o modelo {inferred_model}.

**Fa√ßa sua pergunta sobre a {inferred_model}!**"""
                            st.markdown(success_msg)
                            st.session_state.messages.append({"role": "assistant", "content": success_msg})
                            return  # Sair para n√£o continuar o afunilamento
                        else:
                            # Continuar coletando mais informa√ß√µes
                            new_stage = "features_analyzed"
                            context = analysis
                    else:
                        # N√£o detectou nada √∫til, perguntar mais detalhes
                        if len(st.session_state.collected_features) >= 3:
                            # J√° coletou bastante, pedir para verificar fisicamente
                            new_stage = "features_analyzed"
                        else:
                            # Continuar perguntando
                            new_stage = current_stage
                
                elif current_stage == "features_analyzed":
                    if analysis == "desistiu":
                        new_stage = "desistiu"
                    elif analysis in ["compacta", "media", "grande"]:
                        # Adicionar tamanho √†s caracter√≠sticas
                        st.session_state.collected_features.append(analysis)
                        
                        # Tentar inferir modelo novamente
                        inferred_model = infer_model_from_features(st.session_state.collected_features)
                        if inferred_model:
                            st.session_state.identified_printer = inferred_model
                            st.session_state.identification_stage = None
                            success_msg = f"‚úÖ **Modelo prov√°vel: {inferred_model}!** Posso ajudar com sua {inferred_model}?"
                            st.markdown(success_msg)
                            st.session_state.messages.append({"role": "assistant", "content": success_msg})
                            return
                        else:
                            new_stage = "failed"
                    else:
                        # Verificar se n√£o digitou um modelo
                        possible_model = detect_printer_in_query(prompt)
                        if possible_model:
                            st.session_state.identified_printer = possible_model
                            st.session_state.identification_stage = None
                            success_msg = f"‚úÖ **Perfeito! Modelo {possible_model} identificado!**"
                            st.markdown(success_msg)
                            st.session_state.messages.append({"role": "assistant", "content": success_msg})
                            return
                        else:
                            new_stage = "failed"
                
                elif current_stage == "desistiu":
                    # √öltima chance - verificar se digitou modelo
                    possible_model = detect_printer_in_query(prompt)
                    if possible_model:
                        st.session_state.identified_printer = possible_model
                        st.session_state.identification_stage = None
                        success_msg = f"‚úÖ **√ìtimo! Modelo {possible_model} identificado!**"
                        st.markdown(success_msg)
                        st.session_state.messages.append({"role": "assistant", "content": success_msg})
                        return
                    else:
                        new_stage = "failed"
                
                # Atualizar est√°gio
                st.session_state.identification_stage = new_stage
                
                # Gerar pergunta de afunilamento apropriada
                funnel_response = generate_funnel_question(prompt, new_stage, context)
                st.markdown(funnel_response)
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.messages.append({"role": "assistant", "content": funnel_response})
