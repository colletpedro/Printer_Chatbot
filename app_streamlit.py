#!/usr/bin/env python3
"""
Chatbot Epson - Interface Streamlit
Vers√£o limpa e funcional para deploy
"""

import streamlit as st
import google.generativeai as genai

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Chatbot Epson - Suporte T√©cnico",
    page_icon="üñ®Ô∏è",
    layout="wide"
)

# Configura√ß√£o da API Gemini
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyDjejxDFqTSg_i-KDnS2QqsXdiWLydIrSk")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Lista de modelos suportados
PRINTER_MODELS = [
    "Epson L3110", "Epson L3150", "Epson L3250", "Epson L3251",
    "Epson L375", "Epson L396", "Epson L4150", "Epson L4260",
    "Epson L5190", "Epson L5290", "Epson L6490", "Epson L1300", "Epson L805"
]

# Inicializa√ß√£o do estado
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'response_mode' not in st.session_state:
    st.session_state.response_mode = "detalhado"

def generate_response(query, printer_model=None, mode="detalhado"):
    """Gera resposta usando Gemini"""
    try:
        # Ajusta o prompt baseado no modo
        if mode == "r√°pido":
            mode_instruction = """
            Forne√ßa uma resposta BREVE e DIRETA, em no m√°ximo 3-4 frases.
            V√° direto ao ponto principal sem muitos detalhes.
            """
        else:  # detalhado
            mode_instruction = """
            Forne√ßa uma resposta COMPLETA e DETALHADA.
            Inclua:
            - Explica√ß√£o passo a passo quando aplic√°vel
            - Poss√≠veis causas do problema
            - Solu√ß√µes alternativas se existirem
            - Dicas de preven√ß√£o quando relevante
            """
        
        prompt = f"""Voc√™ √© um especialista em impressoras Epson.
        
        Modelo da impressora: {printer_model if printer_model else 'N√£o especificado'}
        
        {mode_instruction}
        
        Pergunta do usu√°rio: {query}
        
        Responda em portugu√™s de forma clara."""
        
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text
        else:
            return "N√£o foi poss√≠vel gerar resposta. Tente novamente."
            
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# Interface principal
st.title("üñ®Ô∏è Chatbot Epson - Suporte T√©cnico")
st.markdown("Sistema inteligente de suporte para impressoras Epson")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o de impressora
    selected_printer = st.selectbox(
        "üñ®Ô∏è Modelo da Impressora:",
        ["N√£o especificado"] + PRINTER_MODELS
    )
    
    st.markdown("---")
    
    # Modo de resposta
    st.subheader("üí¨ Modo de Resposta")
    response_mode = st.radio(
        "Escolha o tipo de resposta:",
        ["r√°pido", "detalhado"],
        index=1,  # detalhado por padr√£o
        help="R√°pido: respostas diretas e concisas\nDetalhado: explica√ß√µes completas com passo a passo"
    )
    st.session_state.response_mode = response_mode
    
    if response_mode == "r√°pido":
        st.info("‚ö° Respostas r√°pidas e diretas")
    else:
        st.info("üìñ Respostas detalhadas com explica√ß√µes")
    
    st.markdown("---")
    
    # Limpar chat
    if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown("**Vers√£o:** 1.0")
    st.markdown("**Status:** ‚úÖ Online")

# Mostrar mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio
if prompt := st.chat_input("Digite sua pergunta sobre impressoras Epson..."):
    # Adicionar mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Gerar e mostrar resposta
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            response = generate_response(
                prompt, 
                selected_printer if selected_printer != "N√£o especificado" else None,
                mode=st.session_state.response_mode
            )
            st.markdown(response)
    
    # Adicionar resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})
