#!/usr/bin/env python3
"""
Chatbot Epson - Interface Streamlit V2
Vers√£o com sistema de afunilamento melhorado
- Uma pergunta por vez
- Sem loops de perguntas repetidas  
- N√£o responde quando n√£o entende ap√≥s m√∫ltiplas tentativas
"""

import streamlit as st
import google.generativeai as genai
import re

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Chatbot Epson V2 - Suporte T√©cnico",
    page_icon="üñ®Ô∏è",
    layout="wide"
)

# Configura√ß√£o da API Gemini
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyDjejxDFqTSg_i-KDnS2QqsXdiWLydIrSk")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Lista de modelos suportados
PRINTER_MODELS = [
    "Epson L3110", "Epson L3150", "Epson L3250", "Epson L3251",
    "Epson L375", "Epson L396", "Epson L4150", "Epson L4260",
    "Epson L5190", "Epson L5290", "Epson L6490", "Epson L1300", "Epson L805"
]

# Inicializa√ß√£o do estado
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'response_mode' not in st.session_state:
    st.session_state.response_mode = "detalhado"
if 'identified_printer' not in st.session_state:
    st.session_state.identified_printer = None
if 'identification_stage' not in st.session_state:
    st.session_state.identification_stage = None
if 'funnel_features' not in st.session_state:
    st.session_state.funnel_features = {}
if 'funnel_attempt' not in st.session_state:
    st.session_state.funnel_attempt = 0
if 'stage_attempts' not in st.session_state:
    st.session_state.stage_attempts = 0

def normalize_text(text):
    """Normaliza texto para compara√ß√£o mais flex√≠vel"""
    import unicodedata
    import re
    
    # Converter para lowercase
    text = text.lower().strip()
    
    # Remover acentos
    text = ''.join(c for c in unicodedata.normalize('NFD', text) 
                   if unicodedata.category(c) != 'Mn')
    
    # Remover pontua√ß√£o e m√∫ltiplos espa√ßos
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

def detect_printer_in_query(query):
    """Detecta se algum modelo de impressora foi mencionado na pergunta"""
    query_normalized = normalize_text(query)
    
    for model in PRINTER_MODELS:
        # Remove "Epson " do modelo para compara√ß√£o mais flex√≠vel
        model_simple = model.replace("Epson ", "").lower()
        model_normalized = normalize_text(model_simple)
        
        # Verificar varia√ß√µes
        variations = [
            model_normalized,
            model_normalized.replace(" ", ""),
            model_normalized.replace("l", "l "),  # L3150 ‚Üí L 3150
        ]
        
        for variant in variations:
            if variant in query_normalized:
                return model
    return None

def analyze_user_response(prompt, stage):
    """Analisa resposta do usu√°rio de forma linear e clara"""
    prompt_normalized = normalize_text(prompt)
    
    # Respostas muito curtas ou sem contexto - ignorar
    if len(prompt_normalized) < 2:
        return None
    
    # Detec√ß√£o se o usu√°rio desistiu (em qualquer est√°gio)
    if any(word in prompt_normalized for word in ["desisto", "nao consigo", "nao sei mesmo", "deixa pra la", "esquece", "cancela"]):
        return "failed"
    
    # Se o usu√°rio est√° fazendo uma pergunta nova (n√£o relacionada ao afunilamento)
    question_indicators = ["como", "porque", "por que", "quando", "onde", "o que", "qual problema", "ajuda com"]
    if any(indicator in prompt_normalized for indicator in question_indicators):
        # N√£o processar como resposta de afunilamento
        return None
    
    # EST√ÅGIO 1: Identificar tipo (multifuncional ou simples)
    if stage == "initial" or stage is None:
        multifuncional_keywords = [
            "multifuncional", "multi funcional", "mult", "3 em 1", "3em1",
            "copia", "copiar", "digitaliza", "digitalizar", "scanner", "scan",
            "escanear", "xerox", "todas funcoes", "sim ela copia"
        ]
        
        simples_keywords = [
            "so imprime", "apenas imprime", "apenas impressora", "somente imprime",
            "simples", "basica", "nao copia", "nao digitaliza", "sem scanner"
        ]
        
        # Testar tipo
        for keyword in multifuncional_keywords:
            if keyword in prompt_normalized:
                st.session_state.funnel_features['tipo'] = 'multifuncional'
                return "ask_wifi"
        
        for keyword in simples_keywords:
            if keyword in prompt_normalized:
                st.session_state.funnel_features['tipo'] = 'simples'
                return "ask_tanque"
        
        # Respostas sim/n√£o contextuais
        if any(word in prompt_normalized for word in ["sim", "yes", "uhum", "aham", "claro", "isso"]):
            st.session_state.funnel_features['tipo'] = 'multifuncional'
            return "ask_wifi"
        
        if any(word in prompt_normalized for word in ["nao", "no", "nop", "negativo"]):
            st.session_state.funnel_features['tipo'] = 'simples'
            return "ask_tanque"
        
        if any(phrase in prompt_normalized for phrase in ["nao sei", "nao lembro", "nao tenho certeza"]):
            return "need_visual_help"
    
    # EST√ÅGIO 2: Perguntar sobre Wi-Fi (apenas para multifuncionais)
    elif stage == "ask_wifi":
        # Respostas positivas espec√≠ficas para WiFi
        if any(word in prompt_normalized for word in ["wifi", "wi fi", "wireless", "sem fio", "rede wifi"]):
            st.session_state.funnel_features['wifi'] = True
            return "ask_tanque"
        # Resposta gen√©rica "sim" s√≥ se for curta e clara
        elif prompt_normalized in ["sim", "tem", "sim tem", "tem sim", "possui", "sim possui"]:
            st.session_state.funnel_features['wifi'] = True
            return "ask_tanque"
        # Respostas negativas espec√≠ficas
        elif any(word in prompt_normalized for word in ["sem wifi", "nao tem wifi", "cabo", "usb apenas", "fio"]):
            st.session_state.funnel_features['wifi'] = False
            return "ask_tanque"
        # Resposta gen√©rica "n√£o" s√≥ se for curta e clara
        elif prompt_normalized in ["nao", "nao tem", "sem", "negativo", "n", "nop"]:
            st.session_state.funnel_features['wifi'] = False
            return "ask_tanque"
        elif any(phrase in prompt_normalized for phrase in ["nao sei", "nao lembro", "nao tenho certeza"]):
            return "ask_tanque"  # Pula se n√£o souber
        # N√£o entendeu
        return None
    
    # EST√ÅGIO 3: Perguntar sobre tanque de tinta
    elif stage == "ask_tanque":
        # Respostas positivas espec√≠ficas para tanque
        if any(word in prompt_normalized for word in ["tanque", "tank", "ecotank", "eco tank", "refil", "garrafa", "reservatorio"]):
            st.session_state.funnel_features['tanque'] = True
            return "ask_color"
        # Respostas indicando que v√™ tanques
        elif any(phrase in prompt_normalized for phrase in ["vejo tanque", "sim vejo", "vejo sim", "tem tanque"]):
            st.session_state.funnel_features['tanque'] = True
            return "ask_color"
        # Resposta gen√©rica "sim" apenas se for muito clara
        elif prompt_normalized in ["sim", "vejo", "sim tem", "tem sim"]:
            st.session_state.funnel_features['tanque'] = True
            return "ask_color"
        # Respostas negativas espec√≠ficas
        elif any(word in prompt_normalized for word in ["cartucho", "usa cartucho", "sem tanque", "nao vejo tanque"]):
            st.session_state.funnel_features['tanque'] = False
            return "ask_color"
        # Resposta gen√©rica "n√£o" apenas se for clara
        elif prompt_normalized in ["nao", "nao vejo", "nao tem", "usa cartucho"]:
            st.session_state.funnel_features['tanque'] = False
            return "ask_color"
        elif any(phrase in prompt_normalized for phrase in ["nao sei", "nao lembro", "nao tenho certeza"]):
            return "ask_color"  # Pula se n√£o souber
        # N√£o entendeu
        return None
    
    # EST√ÅGIO 4: Perguntar sobre colorida
    elif stage == "ask_color":
        # Respostas positivas espec√≠ficas para colorida
        if any(word in prompt_normalized for word in ["colorida", "colorido", "cores", "color", "cmyk"]):
            st.session_state.funnel_features['colorida'] = True
            return "ask_size"
        # Respostas negativas espec√≠ficas
        elif any(phrase in prompt_normalized for phrase in ["preto e branco", "preto branco", "pb", "monocromatica", "mono", "apenas preto", "so preto"]):
            st.session_state.funnel_features['colorida'] = False
            return "ask_size"
        # Respostas gen√©ricas s√≥ em contexto muito claro
        elif prompt_normalized == "sim" and "color" in str(st.session_state.messages[-2:]).lower():
            st.session_state.funnel_features['colorida'] = True
            return "ask_size"
        elif prompt_normalized == "nao" and "color" in str(st.session_state.messages[-2:]).lower():
            st.session_state.funnel_features['colorida'] = False
            return "ask_size"
        elif any(phrase in prompt_normalized for phrase in ["nao sei", "nao lembro", "nao tenho certeza"]):
            return "ask_size"  # Pula se n√£o souber
        # N√£o entendeu
        return None
    
    # EST√ÅGIO 5: Perguntar sobre tamanho
    elif stage == "ask_size":
        # Tamanhos espec√≠ficos
        if any(word in prompt_normalized for word in ["pequena", "pequeno", "compacta", "mini", "portatil"]):
            st.session_state.funnel_features['tamanho'] = 'pequena'
            return "try_identify"
        elif any(word in prompt_normalized for word in ["media", "medio", "normal", "padrao", "regular"]):
            st.session_state.funnel_features['tamanho'] = 'media'
            return "try_identify"
        elif any(word in prompt_normalized for word in ["grande", "gigante", "robusta", "profissional", "escritorio", "enorme"]):
            st.session_state.funnel_features['tamanho'] = 'grande'
            return "try_identify"
        elif any(phrase in prompt_normalized for phrase in ["nao sei", "nao lembro", "nao tenho certeza"]):
            return "ask_visual_check"
        # N√£o entendeu
        return None
    
    # EST√ÅGIO 6: Tentativa de identifica√ß√£o visual
    elif stage == "ask_visual_check":
        # Procurar por qualquer men√ß√£o de modelo
        pattern = r'[lL]\s*\d{3,4}'
        matches = re.findall(pattern, prompt)
        if matches:
            # Tentar detectar o modelo mencionado
            detected = detect_printer_in_query(prompt)
            if detected:
                st.session_state.identified_printer = detected
                return "model_identified"
        return "failed"
    
    # Estados especiais
    elif stage == "need_visual_help":
        if any(word in prompt_normalized for word in ["tampa", "sim", "tem", "vejo", "abre"]):
            st.session_state.funnel_features['tipo'] = 'multifuncional'
            return "ask_wifi"
        elif any(word in prompt_normalized for word in ["nao", "sem tampa", "nao tem", "nao abre"]):
            st.session_state.funnel_features['tipo'] = 'simples'
            return "ask_tanque"
    
    return None

def generate_contextual_hint(stage):
    """Gera dicas contextuais quando n√£o entende a resposta do usu√°rio"""
    if stage == "initial":
        return """ü§î **N√£o entendi sua resposta...**
        
Por favor, responda de forma simples:
- **"√© multifuncional"** se ela imprime, copia e digitaliza
- **"s√≥ imprime"** se ela apenas imprime
- **"n√£o sei"** se n√£o tiver certeza"""
    
    elif stage == "ask_wifi":
        return """ü§î **N√£o entendi sobre o Wi-Fi...**
        
Tente responder:
- **"sim"** ou **"tem wifi"** se tem conex√£o sem fio
- **"n√£o"** ou **"sem wifi"** se precisa de cabo
- **"n√£o sei"** se n√£o tiver certeza"""
    
    elif stage == "ask_tanque":
        return """ü§î **N√£o entendi sobre os tanques...**
        
Responda:
- **"sim"** ou **"vejo tanques"** se tem reservat√≥rios transparentes de tinta
- **"n√£o"** ou **"usa cartucho"** se usa cartuchos tradicionais
- **"n√£o sei"** se n√£o tiver certeza"""
    
    elif stage == "ask_color":
        return """ü§î **N√£o entendi sobre as cores...**
        
Diga simplesmente:
- **"colorida"** se imprime em cores
- **"preto e branco"** se s√≥ imprime em preto
- **"n√£o sei"** se n√£o tiver certeza"""
    
    elif stage == "ask_size":
        return """ü§î **N√£o entendi sobre o tamanho...**
        
Escolha um:
- **"pequena"** - Compacta, cabe em mesa pequena
- **"m√©dia"** - Tamanho padr√£o de escrit√≥rio
- **"grande"** - Robusta, profissional"""
    
    # Para outros est√°gios, retornar None (n√£o responder)
    return None

def identify_possible_models(features):
    """Identifica poss√≠veis modelos baseado nas caracter√≠sticas coletadas"""
    possible = []
    
    # Mapear caracter√≠sticas para modelos
    if features.get('tipo') == 'multifuncional':
        if features.get('tanque'):
            # Multifuncionais com tanque
            if features.get('wifi'):
                if features.get('colorida', True):
                    if features.get('tamanho') == 'pequena':
                        possible.extend(['L3150', 'L3250'])
                    elif features.get('tamanho') == 'media':
                        possible.extend(['L4260', 'L4150'])
                    else:
                        possible.extend(['L5290', 'L6490'])
                else:
                    possible.append('L5190')  # Mono com tanque
            else:
                # Sem WiFi com tanque
                possible.extend(['L3110', 'L3251'])
        else:
            # Multifuncionais com cartucho
            if features.get('wifi'):
                possible.extend(['L396', 'L375'])
    else:
        # Impressoras simples (n√£o multifuncionais)
        if features.get('tanque'):
            if features.get('tamanho') == 'grande':
                possible.append('L1300')
            else:
                possible.append('L805')
    
    return possible

def generate_funnel_question(query, stage=None):
    """Gera uma pergunta por vez para identificar a impressora"""
    
    # Pergunta inicial
    if stage is None or stage == "initial":
        return """üîç **Preciso identificar sua impressora primeiro!**
        
Para fornecer o melhor suporte, preciso saber o modelo da sua impressora Epson.

**Pergunta r√°pida:**
Sua impressora √© **multifuncional** (imprime, copia e digitaliza) ou **apenas imprime**?

üí° Responda simplesmente: "√© multifuncional" ou "s√≥ imprime\""""
    
    # Ajuda visual para identificar tipo
    elif stage == "need_visual_help":
        return """ü§î **Vamos descobrir juntos!**
        
**Olhe para sua impressora:**
Ela tem uma **tampa em cima que abre** para colocar documentos?
(Isso seria o scanner)

‚úÖ **SIM** = √â multifuncional
‚ùå **N√ÉO** = √â impressora simples"""
    
    # Pergunta sobre Wi-Fi (para multifuncionais)
    elif stage == "ask_wifi":
        features = st.session_state.funnel_features
        tipo = features.get('tipo', '')
        
        return f"""‚úÖ **√ìtimo! Sua impressora √© {tipo}!**
        
**Pr√≥xima pergunta:**
Sua impressora tem **Wi-Fi** (conex√£o sem fio)?

üí° Responda: "sim", "n√£o" ou "n√£o sei"""
    
    # Pergunta sobre tanque
    elif stage == "ask_tanque":
        features = st.session_state.funnel_features
        tipo = features.get('tipo', 'impressora')
        
        tipo_msg = "multifuncional" if tipo == "multifuncional" else "impressora"
        wifi_msg = ""
        if 'wifi' in features:
            wifi_msg = " com Wi-Fi" if features['wifi'] else " sem Wi-Fi"
        
        return f"""‚úÖ **Identificando sua {tipo_msg}{wifi_msg}...**
        
**Pr√≥xima pergunta:**
Voc√™ v√™ **tanques de tinta transparentes** na frente ou lateral da impressora?
(S√£o reservat√≥rios que voc√™ abastece com garrafinhas de tinta)

üí° Responda: "sim vejo" ou "n√£o, usa cartucho"""
    
    # Pergunta sobre cores
    elif stage == "ask_color":
        features = st.session_state.funnel_features
        tanque_msg = " com tanque de tinta" if features.get('tanque') else " com cartucho"
        
        return f"""üìã **Quase l√°! J√° sei que √© uma impressora{tanque_msg}.**
        
**Pr√≥xima pergunta:**
Sua impressora √© **colorida** ou s√≥ **preto e branco**?

üí° Responda: "colorida" ou "preto e branco"""
    
    # Pergunta sobre tamanho
    elif stage == "ask_size":
        features = st.session_state.funnel_features
        return """üéØ **√öltima pergunta!**
        
**Qual o tamanho da sua impressora?**

üìè **Pequena/Compacta** = Cabe facilmente em uma mesa
üìê **M√©dia** = Tamanho padr√£o de escrit√≥rio
üì¶ **Grande** = Robusta, para uso profissional

üí° Responda: "pequena", "m√©dia" ou "grande"""
    
    # Tentativa de identifica√ß√£o
    elif stage == "try_identify":
        features = st.session_state.funnel_features
        
        # Tentar sugerir modelos baseado nas caracter√≠sticas
        sugestoes = identify_possible_models(features)
        
        if sugestoes:
            models_list = "\n".join([f"- **{m}**" for m in sugestoes[:3]])
            return f"""üîç **Baseado nas caracter√≠sticas, pode ser um destes modelos:**
            
{models_list}

**Voc√™ consegue verificar o modelo exato?**
Procure uma etiqueta com "L" seguido de n√∫meros (ex: L3150)

üí° Digite o modelo ou diga "n√£o encontro"""
        else:
            return """‚ùì **Preciso do modelo exato para continuar...**
            
**Por favor, procure o modelo na impressora:**
- Etiqueta na frente, tampa ou atr√°s
- Come√ßa com "L" + n√∫meros (ex: L3150)

üí° Quando encontrar, digite aqui!"""
    
    # Checagem visual final
    elif stage == "ask_visual_check":
        return """üîç **Vamos tentar uma √∫ltima vez!**
        
**Procure com aten√ß√£o:**
1. **Na frente** da impressora (abaixo dos bot√µes)
2. **Na tampa superior** (onde abre o scanner)
3. **Atr√°s** da impressora
4. **Embaixo** (etiqueta com informa√ß√µes)

O modelo sempre come√ßa com **"L"** seguido de 3-4 n√∫meros.
**Exemplo:** L3150, L375, L4260

üí° Digite o que encontrar ou "n√£o achei"""
    
    # Falha na identifica√ß√£o
    elif stage == "failed":
        st.session_state.funnel_attempt += 1
        attempts = st.session_state.funnel_attempt
        
        if attempts < 2:
            return """‚ö†Ô∏è **Ainda n√£o consegui identificar, mas n√£o desista!**
            
**Outras formas de descobrir o modelo:**
1. **No computador:** Configura√ß√µes > Impressoras
2. **Na nota fiscal** ou caixa do produto
3. **No manual** da impressora
4. **No app Epson** do celular

Quando descobrir, digite o modelo aqui! üñ®Ô∏è"""
        else:
            return """‚ùå **N√£o consegui identificar sua impressora**
            
Para sua seguran√ßa, preciso do modelo exato antes de dar instru√ß√µes.

**Use a barra lateral ‚Üí**
Selecione seu modelo no menu dropdown

**Ou digite diretamente:**
"Minha impressora √© L3150" (exemplo)

Estou aqui quando souber o modelo! üñ®Ô∏è"""
    
    # Modelo identificado
    elif stage == "model_identified":
        model = st.session_state.identified_printer
        return f"""‚úÖ **Perfeito! Identifiquei sua {model}!**
        
Agora posso ajudar com qualquer problema ou d√∫vida sobre sua impressora.

**Como posso ajudar voc√™ hoje?** üñ®Ô∏è"""
    
    # Estado desconhecido
    else:
        return """‚ùì **Houve um problema no processo...**
        
**Por favor, me diga:**
Qual o modelo da sua impressora Epson?
(Exemplo: L3150, L375, L4260)

üí° Ou selecione na barra lateral ‚Üí"""

def generate_response(query, printer_model=None, mode="detalhado"):
    """Gera resposta usando Gemini - APENAS se souber o modelo da impressora"""
    
    # N√ÉO responde sem modelo de impressora
    if not printer_model:
        return None
    
    try:
        # Ajusta o prompt baseado no modo
        if mode == "r√°pido":
            mode_instruction = """
            Forne√ßa uma resposta BREVE e DIRETA, em no m√°ximo 3-4 frases.
            V√° direto ao ponto principal sem muitos detalhes.
            IMPORTANTE: Seja espec√≠fico para o modelo de impressora informado.
            """
        else:  # detalhado
            mode_instruction = """
            Forne√ßa uma resposta COMPLETA e DETALHADA.
            Inclua:
            - Explica√ß√£o passo a passo espec√≠fica para este modelo
            - Poss√≠veis causas do problema neste modelo espec√≠fico
            - Solu√ß√µes alternativas se existirem
            - Dicas de preven√ß√£o para este modelo
            IMPORTANTE: Todas as informa√ß√µes devem ser espec√≠ficas para o modelo informado.
            """
        
        prompt = f"""Voc√™ √© um especialista em impressoras Epson.
        
        Modelo da impressora: {printer_model}
        
        {mode_instruction}
        
        REGRA CR√çTICA: Forne√ßa informa√ß√µes ESPEC√çFICAS para o modelo {printer_model}.
        N√£o d√™ respostas gen√©ricas. Se n√£o souber algo espec√≠fico deste modelo, seja honesto.
        
        Pergunta do usu√°rio: {query}
        
        Responda em portugu√™s de forma clara e espec√≠fica para o modelo {printer_model}."""
        
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text
        else:
            return "N√£o foi poss√≠vel gerar resposta. Tente novamente."
            
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# Interface principal
st.title("üñ®Ô∏è Chatbot Epson V2 - Suporte T√©cnico")
st.markdown("Sistema inteligente de suporte para impressoras Epson")
st.markdown("üÜï **Vers√£o 2.1** - Sistema de afunilamento melhorado")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o de impressora
    selected_printer = st.selectbox(
        "üñ®Ô∏è Modelo da Impressora:",
        ["N√£o especificado"] + PRINTER_MODELS
    )
    
    # Atualizar impressora identificada quando selecionada manualmente
    if selected_printer != "N√£o especificado":
        st.session_state.identified_printer = selected_printer
        st.session_state.identification_stage = None
        st.success(f"‚úÖ Modelo identificado: {selected_printer}")
    elif st.session_state.identified_printer:
        st.info(f"üìå Modelo detectado: {st.session_state.identified_printer}")
    
    st.markdown("---")
    
    # Modo de resposta
    st.subheader("üí¨ Modo de Resposta")
    response_mode = st.radio(
        "Escolha o tipo de resposta:",
        ["r√°pido", "detalhado"],
        index=1,  # detalhado por padr√£o
        help="R√°pido: respostas diretas e concisas\nDetalhado: explica√ß√µes completas com passo a passo"
    )
    st.session_state.response_mode = response_mode
    
    if response_mode == "r√°pido":
        st.info("‚ö° Respostas r√°pidas e diretas")
    else:
        st.info("üìñ Respostas detalhadas com explica√ß√µes")
    
    st.markdown("---")
    
    # Limpar chat
    if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
        st.session_state.messages = []
        st.session_state.identified_printer = None
        st.session_state.identification_stage = None
        st.session_state.funnel_features = {}
        st.session_state.funnel_attempt = 0
        st.session_state.stage_attempts = 0
        st.rerun()
    
    # Resetar identifica√ß√£o
    if st.session_state.identified_printer and st.button("üîÑ Trocar Impressora", use_container_width=True):
        st.session_state.identified_printer = None
        st.session_state.identification_stage = None
        st.session_state.funnel_features = {}
        st.session_state.funnel_attempt = 0
        st.session_state.stage_attempts = 0
        st.rerun()
    
    st.markdown("---")
    st.markdown("**Vers√£o:** 2.1 (Melhorada)")
    st.markdown("**Status:** ‚úÖ Online")
    st.markdown("**Modo:** Afunilamento Inteligente")
    st.markdown("üÜï **Melhorias:**")
    st.markdown("- Sem loops")
    st.markdown("- Uma pergunta por vez")
    st.markdown("- An√°lise contextual")

# Mostrar mensagem inicial se n√£o houver hist√≥rico
if not st.session_state.messages and not st.session_state.identified_printer:
    with st.chat_message("assistant"):
        welcome_msg = """üëã **Ol√°! Bem-vindo ao Suporte T√©cnico Epson!**
        
Para fornecer o melhor suporte poss√≠vel, preciso identificar o modelo exato da sua impressora.

**Voc√™ pode:**
1. Selecionar o modelo na barra lateral ‚û°Ô∏è
2. Digitar o modelo diretamente (Ex: "Minha impressora √© L3150")
3. Responder algumas perguntas para eu identificar sua impressora

**Como posso ajudar voc√™ hoje?**"""
        st.markdown(welcome_msg)

# Mostrar mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio
if prompt := st.chat_input("Digite sua pergunta sobre impressoras Epson..."):
    # Adicionar mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Detectar modelo na pergunta
    detected_model = detect_printer_in_query(prompt)
    
    # Atualizar modelo identificado se detectado
    if detected_model:
        st.session_state.identified_printer = detected_model
        st.session_state.identification_stage = None
    
    # Determinar qual modelo usar
    printer_to_use = None
    if selected_printer != "N√£o especificado":
        printer_to_use = selected_printer
    elif st.session_state.identified_printer:
        printer_to_use = st.session_state.identified_printer
    elif detected_model:
        printer_to_use = detected_model
    
    # Gerar e mostrar resposta
    with st.chat_message("assistant"):
        with st.spinner("Processando..."):
            # Se temos um modelo, gerar resposta normal
            if printer_to_use:
                response = generate_response(
                    prompt, 
                    printer_to_use,
                    mode=st.session_state.response_mode
                )
                
                # Adicionar indicador do modelo usado
                response_with_model = f"**[{printer_to_use}]** {response}"
                st.markdown(response_with_model)
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.messages.append({"role": "assistant", "content": response_with_model})
            
            # Se n√£o temos modelo, iniciar afunilamento
            else:
                # Usar fun√ß√£o inteligente de an√°lise
                current_stage = st.session_state.identification_stage
                analysis_result = analyze_user_response(prompt, current_stage)
                
                # Verificar se foi identificado um modelo
                if analysis_result == "model_identified" or st.session_state.identified_printer:
                    # Modelo foi identificado!
                    if st.session_state.identified_printer:
                        funnel_response = generate_funnel_question(prompt, "model_identified")
                        st.markdown(funnel_response)
                        st.session_state.messages.append({"role": "assistant", "content": funnel_response})
                        st.session_state.identification_stage = None  # Resetar est√°gio
                    else:
                        # N√£o deveria chegar aqui, mas por seguran√ßa
                        new_stage = "initial"
                        st.session_state.identification_stage = new_stage
                        funnel_response = generate_funnel_question(prompt, new_stage)
                        st.markdown(funnel_response)
                        st.session_state.messages.append({"role": "assistant", "content": funnel_response})
                else:
                    # Determinar pr√≥ximo est√°gio baseado na an√°lise
                    if analysis_result:
                        # Entendeu a resposta - avan√ßar para pr√≥ximo est√°gio
                        new_stage = analysis_result
                        st.session_state.stage_attempts = 0  # Resetar contador
                        
                        # Atualizar est√°gio
                        st.session_state.identification_stage = new_stage
                        
                        # Gerar pergunta de afunilamento apropriada
                        funnel_response = generate_funnel_question(prompt, new_stage)
                        st.markdown(funnel_response)
                        
                        # Adicionar resposta ao hist√≥rico
                        st.session_state.messages.append({"role": "assistant", "content": funnel_response})
                    else:
                        # N√£o entendeu a resposta
                        st.session_state.stage_attempts += 1
                        
                        # Se √© a primeira vez que n√£o entende, dar dica contextual
                        if st.session_state.stage_attempts == 1:
                            hint_response = generate_contextual_hint(current_stage)
                            if hint_response:
                                st.markdown(hint_response)
                                st.session_state.messages.append({"role": "assistant", "content": hint_response})
                        # Se j√° tentou v√°rias vezes, sugerir usar a sidebar
                        elif st.session_state.stage_attempts >= 2:
                            fallback_msg = """üí° **Dica: Use a barra lateral!**
                            
Se voc√™ souber o modelo, pode selecion√°-lo diretamente no menu dropdown ‚Üí
                            
Ou tente digitar algo como: "Minha impressora √© L3150"""
                            st.markdown(fallback_msg)
                            st.session_state.messages.append({"role": "assistant", "content": fallback_msg})
                            st.session_state.stage_attempts = 0  # Resetar para evitar spam
                        # Caso contr√°rio, n√£o responder nada (como solicitado pelo usu√°rio)
