#!/usr/bin/env python3
"""
Interface Streamlit Ultra-Minimal
Para garantir deploy no Streamlit Cloud
"""

import streamlit as st
import google.generativeai as genai
from datetime import datetime

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Chatbot Epson - Suporte T√©cnico",
    page_icon="üñ®Ô∏è",
    layout="wide"
)

# Configura√ß√£o da API Gemini
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyDjejxDFqTSg_i-KDnS2QqsXdiWLydIrSk")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Lista de modelos suportados
PRINTER_MODELS = [
    "Epson L3110", "Epson L3150", "Epson L3250", "Epson L3251",
    "Epson L375", "Epson L396", "Epson L4150", "Epson L4260",
    "Epson L5190", "Epson L5290", "Epson L6490", "Epson L1300", "Epson L805"
]

# Inicializa√ß√£o do estado
if 'messages' not in st.session_state:
    st.session_state.messages = []

def generate_response(query, printer_model=None):
    """Gera resposta usando Gemini"""
    try:
        prompt = f"""Voc√™ √© um especialista em impressoras Epson.
        
        Modelo da impressora: {printer_model if printer_model else 'N√£o especificado'}
        
        Pergunta do usu√°rio: {query}
        
        Forne√ßa uma resposta √∫til e clara em portugu√™s."""
        
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text
        else:
            return "N√£o foi poss√≠vel gerar resposta. Tente novamente."
            
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# Interface principal
st.title("üñ®Ô∏è Chatbot Epson - Suporte T√©cnico")
st.markdown("Sistema inteligente de suporte para impressoras Epson")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o de impressora
    selected_printer = st.selectbox(
        "Modelo da Impressora:",
        ["N√£o especificado"] + PRINTER_MODELS
    )
    
    # Limpar chat
    if st.button("üóëÔ∏è Limpar Conversa"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown("**Vers√£o:** Minimal")
    st.markdown("**Status:** ‚úÖ Online")

# Mostrar mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio
if prompt := st.chat_input("Digite sua pergunta sobre impressoras Epson..."):
    # Adicionar mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Gerar e mostrar resposta
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            response = generate_response(prompt, selected_printer if selected_printer != "N√£o especificado" else None)
            st.markdown(response)
    
    # Adicionar resposta ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": response})
