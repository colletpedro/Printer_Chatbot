#!/usr/bin/env python3
"""
Script de migra√ß√£o da base de conhecimento JSON para ChromaDB
Customizado para o projeto GeminiMGI - Sistema de Chatbot Epson

Uso:
    python scripts/migrate_to_chromadb.py --json data/manual_complete.json
    
Funcionalidades:
- Combina title + content para busca sem√¢ntica mais rica
- Preserva metadados espec√≠ficos do projeto (printer_model, type, keywords, etc.)
- Valida√ß√£o de dados antes da inser√ß√£o
- Processamento em batches otimizado
- Modelo de embeddings otimizado para portugu√™s
"""

import argparse
import json
import uuid
import os
import sys
from datetime import datetime
import chromadb
from sentence_transformers import SentenceTransformer

# Configura√ß√µes de modelos otimizados
RECOMMENDED_MODELS = {
    "multilingual-e5-small": {
        "name": "intfloat/multilingual-e5-small",
        "type": "e5",
        "description": "E5 Small - R√°pido e eficiente para PT-BR",
        "batch_size": 256
    },
    "multilingual-e5-base": {
        "name": "intfloat/multilingual-e5-base", 
        "type": "e5",
        "description": "E5 Base - Melhor qualidade para PT-BR",
        "batch_size": 128
    },
    "bge-m3": {
        "name": "BAAI/bge-m3",
        "type": "bge",
        "description": "BGE-M3 - Estado da arte, suporte multimodal",
        "batch_size": 64
    },
    "paraphrase-multilingual": {
        "name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "type": "standard",
        "description": "MiniLM Multilingual - Padr√£o confi√°vel",
        "batch_size": 128
    }
}

def get_model_type(model_name):
    """Detecta o tipo de modelo baseado no nome para aplicar prefixos corretos"""
    model_name_lower = model_name.lower()
    
    if "e5" in model_name_lower and "multilingual" in model_name_lower:
        return "e5"
    elif "bge" in model_name_lower:
        return "bge" 
    else:
        return "standard"

def apply_document_prefix(documents, model_type):
    """Aplica prefixos apropriados para documentos baseado no tipo de modelo"""
    if model_type == "e5":
        return [f"passage: {doc}" for doc in documents]
    elif model_type == "bge":
        return [f"passage: {doc}" for doc in documents]  # BGE tamb√©m usa passage:
    else:
        return documents  # Modelos padr√£o n√£o precisam de prefixo

def apply_query_prefix(query, model_type):
    """Aplica prefixos apropriados para consultas baseado no tipo de modelo"""
    if model_type == "e5":
        return f"query: {query}"
    elif model_type == "bge":
        return f"query: {query}"
    else:
        return query  # Modelos padr√£o n√£o precisam de prefixo

def validate_item(item):
    """Valida se o item tem os campos obrigat√≥rios"""
    required_fields = ["id", "printer_model"]
    missing_fields = [field for field in required_fields if not item.get(field)]
    
    if missing_fields:
        print(f"‚ö†Ô∏è  Item {item.get('id', 'SEM_ID')} ignorado - campos obrigat√≥rios ausentes: {missing_fields}")
        return False
    
    # Verifica se tem pelo menos title ou content
    if not item.get("title") and not item.get("content"):
        print(f"‚ö†Ô∏è  Item {item['id']} ignorado - sem title nem content")
        return False
    
    return True

def prepare_text_content(item):
    """Combina title e content para busca sem√¢ntica mais rica"""
    title = item.get("title", "").strip()
    content = item.get("content", "").strip()
    
    if title and content:
        # Limpa o title de caracteres especiais e repeti√ß√µes
        title_clean = title.replace("Se√ß√£o: ", "").strip()
        if len(title_clean) > 100:
            title_clean = title_clean[:100] + "..."
        
        return f"T√çTULO: {title_clean}\n\nCONTE√öDO: {content}"
    elif title:
        return f"T√çTULO: {title}"
    elif content:
        return content
    else:
        return ""

def prepare_metadata(item):
    """Prepara metadados preservando campos espec√≠ficos do projeto"""
    metadata = {
        "printer_model": item.get("printer_model"),
        "type": item.get("type", "geral"),
        "pdf_hash": item.get("pdf_hash"),
        "original_title": item.get("title", ""),
    }
    
    # Adiciona keywords como string (ChromaDB n√£o aceita listas)
    keywords = item.get("keywords", [])
    if keywords:
        # Converte lista para string separada por v√≠rgulas
        metadata["keywords"] = ", ".join(str(k) for k in keywords) if isinstance(keywords, list) else str(keywords)
    
    # Remove campos vazios
    metadata = {k: v for k, v in metadata.items() if v is not None and v != ""}
    
    return metadata

def load_knowledge_base(json_path):
    """Carrega a base de conhecimento do arquivo JSON"""
    print(f"üìÅ Carregando {json_path}...")
    
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # Estrutura espec√≠fica do projeto: {"manual_info": {...}, "sections": [...]}
        if isinstance(data, dict) and "sections" in data:
            items = data["sections"]
            manual_info = data.get("manual_info", {})
            
            print(f"üìä Informa√ß√µes do manual:")
            print(f"   ‚Ä¢ Fonte: {manual_info.get('source', 'N/A')}")
            print(f"   ‚Ä¢ Total de se√ß√µes: {manual_info.get('total_sections', len(items))}")
            print(f"   ‚Ä¢ Processado em: {manual_info.get('processed_at', 'N/A')}")
            
        elif isinstance(data, list):
            items = data
        else:
            raise ValueError("Formato JSON n√£o reconhecido. Esperado: {'sections': [...]} ou lista direta")
        
        print(f"‚úÖ {len(items)} itens carregados do arquivo")
        return items
        
    except FileNotFoundError:
        raise FileNotFoundError(f"Arquivo n√£o encontrado: {json_path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"Erro ao decodificar JSON: {e}")

def process_items(items):
    """Processa e valida os itens para inser√ß√£o no ChromaDB"""
    print("üîç Processando e validando itens...")
    
    processed_items = []
    stats = {
        "total": len(items),
        "valid": 0,
        "invalid": 0,
        "printers": set(),
        "types": set()
    }
    
    for item in items:
        if not validate_item(item):
            stats["invalid"] += 1
            continue
        
        # Prepara o texto combinado
        text_content = prepare_text_content(item)
        if not text_content.strip():
            print(f"‚ö†Ô∏è  Item {item['id']} ignorado - conte√∫do de texto vazio")
            stats["invalid"] += 1
            continue
        
        # Prepara metadados
        metadata = prepare_metadata(item)
        
        processed_item = {
            "id": item["id"],
            "text": text_content,
            "metadata": metadata
        }
        
        processed_items.append(processed_item)
        stats["valid"] += 1
        stats["printers"].add(item["printer_model"])
        stats["types"].add(item.get("type", "geral"))
    
    print(f"üìà Estat√≠sticas do processamento:")
    print(f"   ‚Ä¢ Itens v√°lidos: {stats['valid']}/{stats['total']}")
    print(f"   ‚Ä¢ Itens inv√°lidos: {stats['invalid']}")
    print(f"   ‚Ä¢ Modelos de impressora: {len(stats['printers'])}")
    print(f"   ‚Ä¢ Tipos de conte√∫do: {sorted(stats['types'])}")
    print(f"   ‚Ä¢ Impressoras: {sorted(stats['printers'])}")
    
    return processed_items

def create_chromadb_collection(db_path, collection_name):
    """Cria ou obt√©m a cole√ß√£o do ChromaDB"""
    print(f"üóÑÔ∏è  Inicializando ChromaDB em {db_path}...")
    
    # Cria o diret√≥rio se n√£o existir
    os.makedirs(db_path, exist_ok=True)
    
    client = chromadb.PersistentClient(path=db_path)
    
    # Remove cole√ß√£o existente se houver
    try:
        client.delete_collection(name=collection_name)
        print(f"üóëÔ∏è  Cole√ß√£o existente '{collection_name}' removida")
    except (ValueError, Exception) as e:
        # Cole√ß√£o n√£o existia ou outro erro - isso √© normal na primeira execu√ß√£o
        if "does not exist" in str(e) or "not found" in str(e).lower():
            print(f"üí° Cole√ß√£o '{collection_name}' n√£o existia (primeira execu√ß√£o)")
        else:
            print(f"‚ö†Ô∏è  Aviso ao remover cole√ß√£o: {e}")
    
    # Cria nova cole√ß√£o
    collection = client.create_collection(name=collection_name)
    print(f"‚úÖ Cole√ß√£o '{collection_name}' criada com sucesso")
    
    return client, collection

def insert_embeddings(collection, items, model_name, batch_size):
    """Insere os itens com embeddings na cole√ß√£o"""
    print(f"ü§ñ Carregando modelo {model_name}...")
    model = SentenceTransformer(model_name)
    
    # Detecta tipo de modelo para aplicar prefixos
    model_type = get_model_type(model_name)
    if model_type != "standard":
        print(f"üè∑Ô∏è  Modelo {model_type.upper()} detectado - aplicando prefixos autom√°ticos")
    
    print(f"üìù Inserindo {len(items)} itens em batches de {batch_size}...")
    
    for i in range(0, len(items), batch_size):
        batch = items[i:i+batch_size]
        
        # Prepara dados do batch
        ids = [item["id"] for item in batch]
        documents = [item["text"] for item in batch]
        metadatas = [item["metadata"] for item in batch]
        
        # Aplica prefixos apropriados para documentos
        documents_with_prefix = apply_document_prefix(documents, model_type)
        
        # Gera embeddings com os documentos prefixados
        print(f"üîÑ Processando batch {i//batch_size + 1}/{(len(items)-1)//batch_size + 1}...")
        embeddings = model.encode(documents_with_prefix, normalize_embeddings=True, show_progress_bar=False).tolist()
        
        # Salva metadados do modelo para uso posterior nas consultas
        for metadata in metadatas:
            metadata["model_type"] = model_type
            metadata["model_name"] = model_name
        
        # Insere no ChromaDB (documents originais sem prefixo para exibi√ß√£o)
        collection.add(
            ids=ids,
            documents=documents,  # Documentos originais para exibi√ß√£o
            metadatas=metadatas,
            embeddings=embeddings
        )
        
        print(f"   ‚úÖ Inseridos {min(i+batch_size, len(items))}/{len(items)} itens")
    
    print("üéâ Inser√ß√£o conclu√≠da com sucesso!")

def save_migration_log(db_path, collection_name, stats):
    """Salva log da migra√ß√£o"""
    log_data = {
        "migration_date": datetime.now().isoformat(),
        "collection_name": collection_name,
        "database_path": db_path,
        "statistics": stats
    }
    
    log_path = os.path.join(db_path, "migration_log.json")
    with open(log_path, "w", encoding="utf-8") as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False)
    
    print(f"üìã Log da migra√ß√£o salvo em: {log_path}")

def show_model_options():
    """Mostra op√ß√µes de modelos dispon√≠veis"""
    print("\nü§ñ MODELOS RECOMENDADOS:")
    print("=" * 60)
    for key, config in RECOMMENDED_MODELS.items():
        print(f"Preset: --model-preset {key}")
        print(f"   Nome: {config['name']}")
        print(f"   Tipo: {config['type'].upper()}")
        print(f"   Descri√ß√£o: {config['description']}")
        print(f"   Batch recomendado: {config['batch_size']}")
        print()

def main():
    parser = argparse.ArgumentParser(
        description="Migra√ß√£o da base de conhecimento JSON para ChromaDB",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
EXEMPLOS DE USO:

  # Migra√ß√£o padr√£o (modelo MiniLM)
  python scripts/migrate_to_chromadb.py

  # Usar E5 Base (recomendado para melhor qualidade)
  python scripts/migrate_to_chromadb.py --model-preset multilingual-e5-base

  # Usar BGE-M3 (estado da arte)
  python scripts/migrate_to_chromadb.py --model-preset bge-m3

  # Modelo customizado
  python scripts/migrate_to_chromadb.py --model intfloat/multilingual-e5-small

Para ver op√ß√µes de modelos: python scripts/migrate_to_chromadb.py --show-models
        """
    )
    
    parser.add_argument("--json", default="data/manual_complete.json", 
                       help="Caminho para o arquivo JSON da base de conhecimento")
    parser.add_argument("--db", default="./chromadb_storage", 
                       help="Diret√≥rio para armazenar o banco ChromaDB")
    parser.add_argument("--collection", default="epson_manuals", 
                       help="Nome da cole√ß√£o no ChromaDB")
    parser.add_argument("--model", 
                       help="Modelo de embeddings customizado")
    parser.add_argument("--model-preset", choices=list(RECOMMENDED_MODELS.keys()),
                       default="multilingual-e5-base",
                       help="Preset de modelo recomendado (padr√£o: multilingual-e5-base)")
    parser.add_argument("--batch", type=int,
                       help="Tamanho do batch (autom√°tico baseado no modelo se n√£o especificado)")
    parser.add_argument("--show-models", action="store_true",
                       help="Mostra modelos dispon√≠veis e sai")
    
    args = parser.parse_args()
    
    if args.show_models:
        show_model_options()
        return
    
    # Determina modelo e configura√ß√µes
    if args.model:
        # Modelo customizado
        model_name = args.model
        model_type = get_model_type(model_name)
        batch_size = args.batch or 128  # Padr√£o se n√£o especificado
    else:
        # Usar preset
        preset = RECOMMENDED_MODELS[args.model_preset]
        model_name = preset["name"]
        model_type = preset["type"]
        batch_size = args.batch or preset["batch_size"]  # Usa batch do preset se n√£o especificado
    
    print(f"üìã CONFIGURA√á√ÉO SELECIONADA:")
    print(f"   Modelo: {model_name}")
    print(f"   Tipo: {model_type.upper()}")
    print(f"   Batch size: {batch_size}")
    if model_type != "standard":
        print(f"   Prefixos: ‚úÖ Ativados automaticamente")
    
    try:
        print("üöÄ MIGRA√á√ÉO JSON ‚Üí ChromaDB")
        print("=" * 50)
        
        # 1. Carrega dados
        items = load_knowledge_base(args.json)
        
        # 2. Processa e valida
        processed_items = process_items(items)
        
        if not processed_items:
            print("‚ùå Nenhum item v√°lido encontrado para migra√ß√£o!")
            return
        
        # 3. Cria cole√ß√£o ChromaDB
        client, collection = create_chromadb_collection(args.db, args.collection)
        
        # 4. Insere com embeddings
        insert_embeddings(collection, processed_items, model_name, batch_size)
        
        # 5. Salva log
        stats = {
            "total_items": len(items),
            "migrated_items": len(processed_items),
            "model_used": model_name,
            "model_type": model_type,
            "batch_size": batch_size,
            "preset_used": args.model_preset if not args.model else None
        }
        save_migration_log(args.db, args.collection, stats)
        
        print("\n" + "=" * 50)
        print("‚úÖ MIGRA√á√ÉO CONCLU√çDA COM SUCESSO!")
        print(f"üìä {len(processed_items)} itens migrados para ChromaDB")
        print(f"üóÑÔ∏è  Banco: {args.db}")
        print(f"üìÅ Cole√ß√£o: {args.collection}")
        print(f"üîç Para testar: python scripts/test_chromadb.py")
        
    except Exception as e:
        print(f"\n‚ùå ERRO na migra√ß√£o: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()